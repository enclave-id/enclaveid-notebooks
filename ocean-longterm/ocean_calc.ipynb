{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3929079"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "usage_df = pd.read_csv('usage.csv')\n",
    "usage_df[\"0\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json_repair\n",
    "\n",
    "\n",
    "def extract_json(text):\n",
    "    text = text.replace(\"\\n\", \"\")\n",
    "    start_index = text.rfind(\"{\")\n",
    "    end_index = text.rfind(\"}\")\n",
    "\n",
    "    json_response = {}\n",
    "\n",
    "    if start_index != -1 and end_index != -1 and start_index < end_index:\n",
    "        json_text = text[start_index : end_index + 1]\n",
    "        try:\n",
    "            json_response = json_repair.loads(json_text)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def get_filenames(kind=None, start_date=None, end_date=None):\n",
    "    directory = \"data/google/search_history/\"\n",
    "    file_pattern = r\"^(\\d{4}-\\d{2}-\\d{2})(?:\\.(\\d+))?\\.(?:csv|txt)$\"\n",
    "\n",
    "    def is_date_in_range(file_date):\n",
    "        if start_date is None and end_date is None:\n",
    "            return True\n",
    "        elif start_date is None:\n",
    "            return file_date <= end_date\n",
    "        elif end_date is None:\n",
    "            return start_date <= file_date\n",
    "        else:\n",
    "            return start_date <= file_date <= end_date\n",
    "\n",
    "    def match_kind(file_kind):\n",
    "        if kind is None:\n",
    "            return file_kind is None\n",
    "        else:\n",
    "            return file_kind == str(kind)\n",
    "\n",
    "    filenames = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            match = re.match(file_pattern, file)\n",
    "            if match:\n",
    "                file_date, file_kind = match.groups()\n",
    "                if is_date_in_range(file_date) and match_kind(file_kind):\n",
    "                    filenames.append(os.path.join(root, file))\n",
    "\n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = {\n",
    "  \"openness\": {\n",
    "    \"positive\": [\n",
    "        \"science\", \n",
    "        \"arts and culture\", \n",
    "    ],\n",
    "  },\n",
    "  \"conscientiousness\": {\n",
    "    \"positive\": [\n",
    "        \"organization and planning\", \n",
    "        \"goal-setting and self-improvement\", \n",
    "        \"educational content\", \n",
    "    ],\n",
    "    \"negative\": [\n",
    "        \"random browsing and procrastination\", \n",
    "        \"entertainment-focused\", \n",
    "    ]\n",
    "  },\n",
    "  \"extraversion\": {\n",
    "    \"positive\": [\n",
    "        \"social/extroverted activities\", \n",
    "    ],\n",
    "    \"negative\": [\n",
    "        \"solitary/introspective content\", \n",
    "        \"solo hobbies\",\n",
    "    ]\n",
    "  },\n",
    "  \"agreeableness\": {\n",
    "    \"positive\": [\n",
    "        \"helping others and charity work\", \n",
    "        \"empathy and emotional intelligence\", \n",
    "        \"relationships\", \n",
    "    ],\n",
    "    \"negative\": [\n",
    "        \"competitive content\", \n",
    "        \"critical content\", \n",
    "        \"individual success\",\n",
    "    ]\n",
    "  },\n",
    "  \"neuroticism\": {\n",
    "    \"positive\": [\n",
    "        \"anxiety\", \n",
    "        \"stress management and coping mechanisms\", \n",
    "    ],\n",
    "    \"negative\": [\n",
    "        \"health-related concerns\", \n",
    "        \"relaxation content\",  \n",
    "        \"well-being/positivity\"\n",
    "    ]\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(a, b): \n",
    "    return not set(a).isdisjoint(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Function to return a new defaultdict of dict\n",
    "def defaultdict_of_dict():\n",
    "    return defaultdict(int)\n",
    "\n",
    "def defaultdict_to_dict(d):\n",
    "    if isinstance(d, defaultdict):\n",
    "        d = {k: defaultdict_to_dict(v) for k, v in d.items()}\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_errors = 0\n",
    "counter = defaultdict(defaultdict_of_dict)\n",
    "interests = set()\n",
    "\n",
    "for file in get_filenames(0):\n",
    "    with open(file, \"r\") as f:\n",
    "        text = f.read()\n",
    "        tags = extract_json(text)\n",
    "\n",
    "        if \"narrow_interests\" in tags:\n",
    "            interests.update(tags[\"narrow_interests\"])\n",
    "\n",
    "        if \"broad_categories\" not in tags:\n",
    "            json_errors +=1\n",
    "        else:\n",
    "            bc = tags[\"broad_categories\"]\n",
    "\n",
    "            for trait, values in markers.items():\n",
    "                for polarity, keywords in values.items():\n",
    "                    if intersection(bc, keywords):\n",
    "                        counter[trait][polarity] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9012"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(interests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_days = len(get_filenames(0)) - json_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conscientiousness': {'positive': 1207, 'negative': 697},\n",
       " 'extraversion': {'negative': 724, 'positive': 147},\n",
       " 'openness': {'positive': 620},\n",
       " 'agreeableness': {'negative': 365, 'positive': 173},\n",
       " 'neuroticism': {'positive': 155, 'negative': 608}}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = defaultdict_to_dict(counter)\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conscientiousness': 0.7011041009463722,\n",
       " 'extraversion': 0.2724763406940063,\n",
       " 'openness': 0.7444794952681388,\n",
       " 'agreeableness': 0.4242902208201893,\n",
       " 'neuroticism': 0.32137223974763407}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_scores = {}\n",
    "for trait, values in counter.items():\n",
    "    positive = values.get('positive', 0)\n",
    "    negative = values.get('negative', 0)\n",
    "    normalized_score = (positive - negative) / total_days / 2  # Dividing by 2 to scale to -0.5 to +0.5\n",
    "    normalized_scores[trait] = normalized_score + 0.5 # Adding 0.5 baseline\n",
    "\n",
    "normalized_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 9012 interests out of 9012\n",
      "ChatCompletionMessage(content='```json\\n{\\n  \"modifier\": 0.25\\n}\\n```\\n\\nThe reason for the modifier value of 0.25 is based on the diversity and breadth of interests and topics provided. The list indicates an array of subjects, ranging from arts, culture, science, technology, gaming, history, psychology, finance, and global events, suggesting a high degree of openness to experienceâ€”characteristic of intellectual curiosity and a willingness to engage with a wide variety of ideas. This positive modifier acknowledges the exploration of complex and varied fields, which complements the baseline \"openness\" score by reflecting an individual\\'s nuanced and expansive set of interests.', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ChatCompletionMessage' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/workdir/.venv/lib64/python3.12/site-packages/pydantic/main.py:753\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 753\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpydantic_extra\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'replace'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[161], line 72\u001b[0m\n\u001b[1;32m     68\u001b[0m result \u001b[38;5;241m=\u001b[39m completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n\u001b[0;32m---> 72\u001b[0m json_answer \u001b[38;5;241m=\u001b[39m \u001b[43mextract_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[148], line 5\u001b[0m, in \u001b[0;36mextract_json\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_json\u001b[39m(text):\n\u001b[0;32m----> 5\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m     start_index \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mrfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m     end_index \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mrfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/workdir/.venv/lib64/python3.12/site-packages/pydantic/main.py:755\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pydantic_extra[item]\n\u001b[1;32m    754\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m--> 755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, item):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ChatCompletionMessage' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "openai_model = 'gpt-4-1106-preview'\n",
    "\n",
    "context_length = {\n",
    "    'gpt-4': 1024*8,\n",
    "    'gpt-4-32k': 1024*32,\n",
    "    'gpt-4-1106-preview': 1024*128\n",
    "}\n",
    "\n",
    "import os, tiktoken\n",
    "import openai\n",
    "import random\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "output_tokens = 1000\n",
    "max_context = context_length[openai_model] - output_tokens\n",
    "encoding = tiktoken.encoding_for_model(openai_model)\n",
    "get_n_tokens = lambda text: len(encoding.encode(text))\n",
    "\n",
    "\n",
    "prompt_base = f\"\"\"\n",
    "I am conduncting an analysis to estimate my \"openness\" personality trait based on my Google search history.\n",
    "After a prelimiary analysis, I arrived to a baseline score of {normalized_scores['openness']:.2f}, by taking into account how often I search for topics related to science, arts and culture.\n",
    "\n",
    "To improve the accuracy of the score, I want to take into the account the diversity (or lack thereof) of my more fine grained interests.\n",
    "I will now provide you a summary of my interests extracted from my Google search history over a period of 5 years.\n",
    "After the analysis, provide a JSON object with a \"modiefier\" value between -0.5 an 0.5, which will be added or subtracted to the baseline score.\n",
    "\n",
    "Here is the list of interests:\n",
    "\\n\\n\n",
    "\"\"\"\n",
    "\n",
    "def get_prompt(interests):\n",
    "    prompt_base_tokens = get_n_tokens(prompt_base)\n",
    "    interest_tokens = [get_n_tokens(interest) for interest in interests]\n",
    "    total_interest_tokens = sum(interest_tokens) + len(interests) # account for separators\n",
    "\n",
    "    # Truncate the interests array if the total number of tokens exceeds max_context\n",
    "    if prompt_base_tokens + total_interest_tokens > max_context:\n",
    "        remaining_tokens = max_context - prompt_base_tokens\n",
    "        truncated_interests = []\n",
    "        current_tokens = 0\n",
    "        for i, interest_token in enumerate(interest_tokens):\n",
    "            if current_tokens + interest_token <= remaining_tokens:\n",
    "                truncated_interests.append(interests[i])\n",
    "                current_tokens += interest_token\n",
    "            else:\n",
    "                break\n",
    "    else:\n",
    "        truncated_interests = interests\n",
    "\n",
    "    print(f\"Saved {len(truncated_interests)} interests out of {len(interests)}\")\n",
    "\n",
    "    return f\"{prompt_base}{\",\".join(truncated_interests)}\"\n",
    "\n",
    "data = list(map(str, interests))\n",
    "random.shuffle(data)\n",
    "\n",
    "client = openai.OpenAI(api_key= os.environ[\"OPENAI_API_KEY\"])\n",
    "completion = client.chat.completions.create(\n",
    "  model=openai_model,\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": get_prompt(data)},\n",
    "  ],\n",
    "  max_tokens=output_tokens\n",
    ")\n",
    "\n",
    "result = completion.choices[0].message\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'modifier': 0.25}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_answer = extract_json(result.content)\n",
    "json_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
