{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI\n",
    "import os\n",
    "client = AsyncOpenAI(api_key = os.environ['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt_1(data):\n",
    "    return (\n",
    "        \"Here is some recent google search activity.\"\n",
    "        \" What is the user doing throughout the day?\\n\\n\"\n",
    "    ) + data\n",
    "\n",
    "\n",
    "def get_prompt_2():\n",
    "    return (\n",
    "        \"which of these topics can be classified as proactive intents (endogenous, proactive \"\n",
    "        \"knowledge seeking, long term) and which as reactive intents \"\n",
    "        \"(exogenous, reactive knowledge seeking, short term)?\"\n",
    "    )\n",
    "\n",
    "\n",
    "def get_prompt_3():\n",
    "    return (\n",
    "        \"Can you format the previous answer in a json object? the root object should have\"\n",
    "        \" the fields: reactive, proactive; and the type of these fields should be an array\"\n",
    "        \" with items with fields: title, description, time_start, time_end\"\n",
    "    )\n",
    "\n",
    "\n",
    "async def get_clusters(raw_data):\n",
    "    response = await client.chat.completions.create(\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": get_prompt_1(raw_data)},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "async def classify_clusters(raw_data, cluster_data):\n",
    "    response = await client.chat.completions.create(\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": get_prompt_1(raw_data)},\n",
    "            {\"role\": \"assistant\", \"content\": cluster_data},\n",
    "            {\"role\": \"user\", \"content\": get_prompt_2()},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "async def get_json(raw_data, cluster_data, intent_data):\n",
    "    response = await client.chat.completions.create(\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant designed to output JSON.\"},            {\"role\": \"user\", \"content\": get_prompt_1(raw_data)},\n",
    "            {\"role\": \"assistant\", \"content\": cluster_data},\n",
    "            {\"role\": \"user\", \"content\": get_prompt_2()},\n",
    "            {\"role\": \"assistant\", \"content\": intent_data},\n",
    "            {\"role\": \"user\", \"content\": get_prompt_3()},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "# get all file names in the data folder\n",
    "file_names = os.listdir('raw_data')\n",
    "raw_data = []\n",
    "\n",
    "# for each file name, read the file and get the completion asynchronously\n",
    "for file_name in file_names:\n",
    "    with open('raw_data/' + file_name, 'r') as f:\n",
    "        raw_data.append(f.read())\n",
    "\n",
    "awaitables = []\n",
    "for rd in raw_data:    \n",
    "    awaitables.append(get_clusters(rd))\n",
    "\n",
    "# wait for all completions to finish\n",
    "cluster_data = await asyncio.gather(*awaitables)\n",
    "\n",
    "for i in range(len(file_names)):\n",
    "    with open('out/' + file_names[i] + '-clustered.txt', 'w') as f:\n",
    "        f.write(cluster_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "awaitables = []\n",
    "for (rd, cd) in zip(raw_data, cluster_data):\n",
    "    awaitables.append(classify_clusters(rd, cd))\n",
    "\n",
    "intent_data = await asyncio.gather(*awaitables)\n",
    "\n",
    "for i in range(len(file_names)):\n",
    "    with open('out/' + file_names[i] + '-classified.txt', 'w') as f:\n",
    "        f.write(intent_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "awaitables = []\n",
    "for (rd, cd, id) in zip(raw_data, cluster_data, intent_data):\n",
    "    awaitables.append(get_json(rd, cd, id))\n",
    "\n",
    "json_data = await asyncio.gather(*awaitables)\n",
    "\n",
    "for i in range(len(file_names)):\n",
    "    with open('out/' + file_names[i] + '-final.json', 'w') as f:\n",
    "        f.write(json_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate each .json file against schema.json\n",
    "from jsonschema import validate\n",
    "import json\n",
    "\n",
    "with open('schema.json', 'r') as f:\n",
    "    schema = json.load(f)\n",
    "\n",
    "for file_name in file_names:\n",
    "    with open('out/' + file_name + '-final.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "        validate(instance=data, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove \".csv\" from all filenames inside the data folder\n",
    "import os\n",
    "\n",
    "file_names = os.listdir('out')\n",
    "\n",
    "for file_name in file_names:\n",
    "    os.rename('out/' + file_name, 'out/' + file_name.replace('.csv', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json,os \n",
    "\n",
    "files = [f for f in os.listdir('out') if f.endswith('.json')]\n",
    "reactive = {}\n",
    "proactive = {}\n",
    "\n",
    "for f in files:\n",
    "    with open('out/' + f, 'r') as f:\n",
    "        string = f.read()\n",
    "        date = f.name[4:-11]\n",
    "        reactive[date] = json.loads(string)[\"reactive\"]\n",
    "        proactive[date] = json.loads(string)[\"proactive\"]\n",
    "\n",
    "# sort the dictionary by date\n",
    "reactive = dict(sorted(reactive.items()))\n",
    "proactive = dict(sorted(proactive.items()))\n",
    "\n",
    "with open('summaries/reactive.json', 'w') as f:\n",
    "    json.dump(reactive, f)\n",
    "\n",
    "with open('summaries/proactive.json', 'w') as f:\n",
    "    json.dump(proactive, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
